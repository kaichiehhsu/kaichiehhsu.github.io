---
title: 		"Sim-to-Lab-to-Real"
collection:	ongoing
permalink: 	/research/sim2lab2real
excerpt:    '<img src="/images/Sim-to-Lab-to-Real/sim_to_lab_to_real.png"  alt="drawing" width="800"/>'
date: 		2022-01-20
venue: arXiv (preprint)
paperurl: 'https://arxiv.org/abs/2201.08355'
tags:
  - Safe Reinforcement Learning
  - HJ Reachability Analysis
  - PAC-Bayes Control
---

<center>
	<img src="/images/Sim-to-Lab-to-Real/sim_to_lab_to_real.png"  alt="drawing" width="800"/>
</center>

<center>
	<a href="https://sites.google.com/princeton.edu/sim-to-lab-to-real" class="btn btn-success">
		<span style="font-size: 120%;">
			Project Website
		</span>
	</a>
</center>


1. We leverage a middle-level training stage, *Lab*, between *Sim* and *Real* to safely close the Sim-to-Real gap in ego-vision indoor navigation task. Compared to Sim training, Lab training is (1) more realistic and (2) more safety-critical.

2. For safe Sim-to-Lab transfer, we learn a safety critic with *Hamilton-Jacobi reachability-based RL* and apply a supervisory control scheme to shield unsafe actions during exploration.

3. For safe Lab-to-Real transfer, we use the *Probably Approximately Correct (PAC)-Bayes Control* framework to provide lower bounds (70-90%) on the expected performance and safety of policies in unseen environments.