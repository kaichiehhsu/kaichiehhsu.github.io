---
title: 		"ISAACS: Iterative Soft Adversarial Actor Critic for Safety"
collection:	research
permalink: 	/research/isaacs
excerpt:    '<img src="/images/ISAACS/overview.png"  alt="drawing" width="400"/>'
date: 		2023-06-14
venue: 		'L4DC'
tags:
  - Safety Filter
  - Reinforcement Learning
  - HJ Reachability Analysis
---

<center>
	<img src="/images/ISAACS/overview.png"  alt="drawing" width="300px"/>
</center>

<center>
	<a href="https://proceedings.mlr.press/v211/hsu23a.html" target="_blank" class="btn btn-danger">
		<span style="font-size: 120%;">
		    L4DC paper
		</span>
	</a>
    &nbsp;
	<a href="https://saferobotics.princeton.edu/research/isaacs" class="btn btn-success">
		<span style="font-size: 120%;">
			Project Website
		</span>
	</a>
	&nbsp;
	<a href="https://github.com/SafeRoboticsLab/ISAACS" class="btn btn-success">
		<span style="font-size: 120%;">
			GitHub Code
		</span>
	</a>
</center>

ISAACS (Iterative Soft Adversarial Actor-Critic for Safety) is a new game-theoretic reinforcement learning scheme for approximate safety analysis, whose simulation-trained control policies can be efficiently converted at runtime into robust safety-certified control strategies, allowing robots to plan and operate with safety guarantees in the physical world.

<p class="double_underline">Recommended citation:</p>
```
@inproceedings{hsunguyen2023isaacs,
    title={ISAACS: Iterative Soft Adversarial Actor-Critic for Safety},
    author={Hsu, Kai-Chieh and Nguyen, Duy Phuong and Fisac, Jaime Fern\`andez},
    booktitle={Proceedings of the 5th Annual Learning for Dynamics and Control Conference},
    page={90â€”103} 
    year={2023},
    editor={Matni, Nikolai and Morari, Manfred and Pappas, George J.},
    volume={211},
    series={Proceedings of Machine Learning Research},
    month={15--16 Jun},
    publisher={PMLR},
    url={https://proceedings.mlr.press/v211/hsu23a.html}
}
```